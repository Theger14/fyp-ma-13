{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88cdc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @inproceedings{karkkainenfairface,\n",
    "#   title={FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age for Bias Measurement and Mitigation},\n",
    "#   author={Karkkainen, Kimmo and Joo, Jungseock},\n",
    "#   booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},\n",
    "#   year={2021},\n",
    "#   pages={1548--1558}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b4db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7a537-c430-4f0f-bb05-779a769bb41b",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "1. Combine training and validation dataset\n",
    "    - There's no visual difference between them so might as well combine\n",
    "2. Filter them according to a face recognition algo\n",
    "    - HAAR cascade\n",
    "    - Only keep images that have a detectable face\n",
    "3. Split dataset into 70/20/10 (training/validation/testing)\n",
    "4. Perturb 10% of the dataset:\n",
    "    - Makeup\n",
    "    - Glasses\n",
    "    - Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876c18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairface_train = pd.read_csv(\"fairface_label_train.csv\")\n",
    "fairface_val = pd.read_csv(\"fairface_label_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3caeba68-a798-4d04-a575-e066379e4a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>5162</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>5792</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  age  race  service_test\n",
       "gender                               \n",
       "Female  5162    9     7             2\n",
       "Male    5792    9     7             2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairface_val.groupby(\"gender\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8122299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_filenames(dataset):\n",
    "    male_state = dataset['gender'] == 'Male'\n",
    "    female_state = dataset['gender'] == 'Female'\n",
    "    male = dataset[male_state]\n",
    "    female = dataset[female_state]\n",
    "    \n",
    "    male_filenames = []\n",
    "    for i in tqdm(range(len(male)), \"Loading male files...\"):\n",
    "        male_filenames.append(male.iloc[i]['file'])\n",
    "        \n",
    "    female_filenames = []\n",
    "    for i in tqdm(range(len(female)), \"Loading female files...\"):\n",
    "        female_filenames.append(female.iloc[i]['file'])\n",
    "    return male_filenames, female_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "006b4789-b94d-44c3-9709-23dc73368d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading male files...: 100%|██████████| 45986/45986 [00:05<00:00, 9191.55it/s]\n",
      "Loading female files...: 100%|██████████| 40758/40758 [00:04<00:00, 9264.34it/s]\n"
     ]
    }
   ],
   "source": [
    "male_filenames, female_filenames = give_filenames(fairface_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d99ce9",
   "metadata": {},
   "source": [
    "## For Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2df84423-ae28-48cd-99d0-c7f8a1f144bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files...: 100%|██████████| 45986/45986 [00:00<00:00, 52379.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split training dataset to male and female\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "for i in tqdm(range(len(male_filenames)), desc=\"Loading files...\"):\n",
    "    file = male_filenames[i]\n",
    "    filename_from = os.path.join('fairface-img-margin025-trainval/', file)\n",
    "    filename_to = os.path.join('male/', file[6:])  #     os.rename(filename_from, filename_to)\n",
    "    try:\n",
    "        if (os.path.exists(filename_from)):\n",
    "            shutil.move(filename_from, filename_to)\n",
    "            os.replace(filename_from, filename_to)\n",
    "            filein.close()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fffeb",
   "metadata": {},
   "source": [
    "## For Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78617d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading male files...: 100%|██████████| 5792/5792 [00:00<00:00, 9143.75it/s]\n",
      "Loading female files...: 100%|██████████| 5162/5162 [00:00<00:00, 9247.03it/s]\n"
     ]
    }
   ],
   "source": [
    "male_fn, female_fn = give_filenames(fairface_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df014afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files...: 100%|██████████| 5162/5162 [00:00<00:00, 54718.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split val dataset to male and female\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "for i in tqdm(range(len(female_fn)), desc=\"Loading files...\"):\n",
    "    file = female_fn[i]\n",
    "    filename_from = os.path.join('fairface-img-margin025-trainval/', file)\n",
    "    filename_to = os.path.join('female/', file[4:])\n",
    "#     os.rename(filename_from, filename_to)\n",
    "    try:\n",
    "        if (os.path.exists(filename_from)):\n",
    "            shutil.move(filename_from, filename_to)\n",
    "            os.replace(filename_from, filename_to)\n",
    "            filein.close()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df801ef",
   "metadata": {},
   "source": [
    "## Make Up Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce20a733-2bce-4644-ae79-7401a32d3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c3bc1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "def appl_makeup(filename, output_fn):\n",
    "    \"\"\"\n",
    "    Applies make up filter on a single image and saves it to a given directory.\n",
    "    \n",
    "    filename : str\n",
    "        Input image\n",
    "    output_fn : str\n",
    "        Output image to save\n",
    "    \"\"\"\n",
    "    # Load the jpg file into a numpy array\n",
    "    image = face_recognition.load_image_file(filename)\n",
    "\n",
    "    # Find all facial features in all the faces in the image\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "    pil_image = Image.fromarray(image)\n",
    "    for face_landmarks in face_landmarks_list:\n",
    "        d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "\n",
    "        # Make the eyebrows into a nightmare\n",
    "        d.polygon(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 128))\n",
    "        d.polygon(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 128))\n",
    "        d.line(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "        d.line(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "\n",
    "        # Gloss the lips\n",
    "        d.polygon(face_landmarks['top_lip'], fill=(150, 0, 0, 128))\n",
    "        d.polygon(face_landmarks['bottom_lip'], fill=(150, 0, 0, 128))\n",
    "        d.line(face_landmarks['top_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "        d.line(face_landmarks['bottom_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "\n",
    "        # Sparkle the eyes\n",
    "        d.polygon(face_landmarks['left_eye'], fill=(255, 255, 255, 30))\n",
    "        d.polygon(face_landmarks['right_eye'], fill=(255, 255, 255, 30))\n",
    "\n",
    "        # Apply some eyeliner\n",
    "        d.line(face_landmarks['left_eye'] + [face_landmarks['left_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "        d.line(face_landmarks['right_eye'] + [face_landmarks['right_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "        fn = Path(output_fn)\n",
    "        if not fn.is_dir():\n",
    "            pil_image.save(output_fn)    # Change this to male or female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a0cc1",
   "metadata": {},
   "source": [
    "## Make Up for Male Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "856cd4ee-da9d-427f-b6b5-c3fea019a533",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fairface_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-ea7eaa40a315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmale_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfemale_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgive_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfairface_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fairface_train' is not defined"
     ]
    }
   ],
   "source": [
    "male_fn, female_fn = give_filenames(fairface_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964468c2-728e-4abc-9de5-5aeeaa4a66e0",
   "metadata": {},
   "source": [
    "## Glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d643ba-ad85-4fcd-b0bc-0ce94c8687b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insta_filters.put_glasses import run_filter\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1859b8-831b-437b-ba7e-b672772c5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ddca7f-9d14-4478-a94c-16e4489de304",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='1513.jpg'\n",
    "img=cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    cv2.imwrite(\"test.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b841d218-7b4a-42d1-a752-9cf50c8c6a20",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roi_gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d3bed63d9bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meye_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_gray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'roi_gray' is not defined"
     ]
    }
   ],
   "source": [
    "eye_cascade.detectMultiScale(roi_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561f81c-43d3-4bcc-b5e2-e3e57c22524b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
