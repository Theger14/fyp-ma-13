{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6098bd5-d7f3-45bc-926a-17b4dae25edf",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Import libraries and initialise global variables\n",
    "2. Load data\n",
    "3. Data augmentation\n",
    "4. Load base models\n",
    "5. Model creation using transfer learning\n",
    "    - Base models (from step 4) are used here\n",
    "6. Model training\n",
    "7. Model Analysis\n",
    "    - Get model statistics\n",
    "8. Findings and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d1de6-d1fc-443d-afa5-1acaf7eff7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from gen_results import gen_save_cr_cm # Load test results\n",
    "\n",
    "from tqdm import tqdm            # Progress bar\n",
    "from pathlib import Path         # Create new folder if does not exist\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "# Set if memory growth should be enabled for a PhysicalDevice.\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacdefb-605b-498b-a58f-5415fade8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise global variables\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "IMG_SIZE = (224,224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "LABELS = [\"female\", \"male\"]\n",
    "set_nums = [1,5,8,10]            # List of set numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d26ed0-7843-4e3a-a874-7b31a6ef24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "train_dataset = image_dataset_from_directory(os.path.join(preprocessing_fp, \"train\"),\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE)\n",
    "# Load validation dataset\n",
    "validation_dataset = image_dataset_from_directory(os.path.join(preprocessing_fp, \"val\"),\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945efd8-0db2-4841-902a-c155f900513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19f090-19c6-4a37-8283-6a20916a970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV3 Large base model\n",
    "preprocess_input_mobile = tf.keras.applications.mobilenet_v3.preprocess_input\n",
    "base_model_mobile = tf.keras.applications.MobileNetV3Large(\n",
    "    input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "# Load DenseNet 201 base model\n",
    "preprocess_input_dense = tf.keras.applications.densenet.preprocess_input\n",
    "base_model_dense = tf.keras.applications.densenet.DenseNet201(\n",
    "    input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "# Load ResNet50 base model\n",
    "preprocess_input_res = tf.keras.applications.resnet50.preprocess_input\n",
    "base_model_res = tf.keras.applications.resnet50.ResNet50(\n",
    "    input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80732b5-5fcb-44fb-bc8e-0cdf50e01ecf",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4084c8-755d-4879-9a56-7ad00c7ac399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base_model, preprocess_input):\n",
    "    \"\"\"\n",
    "    Creates a new neural network model applying transfer learning.\n",
    "    \n",
    "    base_model : tf.keras.Model\n",
    "        Base model we use for transfer learning\n",
    "    preprocess_input : Function\n",
    "        Function to perform preprocessing of input images for model compatibility\n",
    "    \"\"\"\n",
    "    global train_dataset\n",
    "    \n",
    "    # Converts images into a 5x5x1280 block of features\n",
    "    image_batch, label_batch = next(iter(train_dataset))\n",
    "    feature_batch = base_model(image_batch)\n",
    "    \n",
    "    # Freeze all convolutional base\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add classification head\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    feature_batch_average = global_average_layer(feature_batch)\n",
    "    \n",
    "    # Model building\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1024, kernel_regularizer='l2', activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1024, kernel_regularizer='l2', activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(512, kernel_regularizer='l2', activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    base_learning_rate = 0.0001\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d62499-db25-49c7-a71b-7518aafe6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the three different models\n",
    "model_mobile = create_model(base_model_mobile, preprocess_input_mobile)\n",
    "model_dense = create_model(base_model_dense, preprocess_input_dense)\n",
    "model_res = create_model(base_model_res, preprocess_input_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecd932-a33a-492d-b092-8bf75d7f3b5c",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8a2c9-94f8-465b-a776-9bccc92bdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, set_no, model_type):\n",
    "    \"\"\"\n",
    "    Trains model, and saves model's best weights and history\n",
    "    \n",
    "    model : \n",
    "        Model to train \n",
    "    set_no : int\n",
    "        Set number\n",
    "    model_type : str\n",
    "        Type of model (i.e. 'mobile', 'dense', 'res')\n",
    "    \"\"\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"best_weights/set{}/model_tl_best_weights_{}_set{}.h5\".format(set_no, model_type, set_no),\n",
    "        monitor=\"loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=5,\n",
    "                                                     mode='max')\n",
    "    \n",
    "    # Save a checkpoint of the model for later use\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_dataset,\n",
    "                             epochs=EPOCHS,\n",
    "                             validation_data=validation_dataset,\n",
    "                            callbacks=[checkpoint, early_stopping])\n",
    "    time_taken = \"%.2fs\" % (time.time() - start_time)\n",
    "    history.history['time_taken'] = time_taken\n",
    "\n",
    "    \n",
    "    target = \"history/set{}\".format(str(set_no)) # Store model history as a JSON file\n",
    "    with open(os.path.join(target, \"model_tl_history_{}_set{}.json\".format(suffix, set_no)), \"w\") as f:\n",
    "        json.dump(history.history, f) # Construct the baseline (unperturbed) model\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd140b-c88c-48a2-9d73-1e75ab4e6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_weights_and_history(set_no):\n",
    "    \"\"\"\n",
    "    Gets model best weights from training and history\n",
    "    \n",
    "    set_no : int\n",
    "        Set number\n",
    "    \"\"\"\n",
    "    history_mobile = model_training(model_mobile,  set_no, 'mobile')\n",
    "    history_dense = model_training(model_dense, set_no, 'dense')\n",
    "    history_res = model_training(model_res, set_no, 'res')\n",
    "    return history_mobile, history_dense, history_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536eecc8-bffc-4426-ac0f-4038c870ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_models_all_sets():\n",
    "    \"\"\"\n",
    "    This function does two things:\n",
    "    1. Builds all three model types (MobileNet, ResNet50, DenseNet)\n",
    "    2. Saves model with the best weights and history\n",
    "    \n",
    "    debiased : boolean\n",
    "        Determines whether we are training a debiased model or not\n",
    "    EPOCHS : int\n",
    "        Number of epochs\n",
    "    \"\"\"\n",
    "    for set_no in tqdm(set_numbers, \"Loading models...\"):\n",
    "        print(\"Training...\")\n",
    "        histories = find_best_weights_and_history(set_no)\n",
    "        print(\"Saving...\")\n",
    "        print(\"--------------------------------\")\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67200b10-6764-4eef-9fcf-b30ef67feb85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gen_models_all_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d051d1e-1d22-48eb-b081-d49a951a9790",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e6726-c232-406f-b4b8-4a84c240a14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_models(set_no, best_w_fp=\"best_weights/\"):\n",
    "    \"\"\"\n",
    "    Returns a list of Keras models from a specific set \n",
    "    \n",
    "    set_no : int\n",
    "        Set number\n",
    "    best_w_fp : str\n",
    "        File path where the best weights of the models for the particular set is stored\n",
    "    \"\"\"\n",
    "    target = best_w_fp + \"set\" + str(set_no) + \"/\"\n",
    "    mobilenet = tf.keras.models.load_model(target + 'model_tl_best_weights_mobile_set{}.h5'.format(str(set_no)))\n",
    "    densenet = tf.keras.models.load_model(target + 'model_tl_best_weights_dense_set{}.h5'.format(str(set_no)))\n",
    "    resnet = tf.keras.models.load_model(target + 'model_tl_best_weights_res_set{}.h5'.format(str(set_no)))\n",
    "    all_models = [mobilenet, densenet, resnet]\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716986e1-392d-4811-bdbe-a8a16432f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_result_for_sets(all_models, original, target):\n",
    "    \"\"\"\n",
    "    Call this function to generate Classification Reports and confusion Matrix results\n",
    "    \n",
    "    all_models : list\n",
    "        List of Keras models\n",
    "    original : str\n",
    "        Original file path\n",
    "    target : str\n",
    "        Target file path\n",
    "    \"\"\"\n",
    "    # Classification reports and confusion matrices for MobileNet\n",
    "    cr_mobile_all, cm_mobile_all = gen_save_cr_cm('mobile', all_models, original, target, perturbation=test_type, gender=None) # Both\n",
    "    # Classification reports and confusion matrices for DenseNet\n",
    "    cr_dense_all, cm_dense_all = gen_save_cr_cm('dense', all_models, original, target, perturbation=test_type, gender=None) # Both\n",
    "    # Classification reports and confusion matrices for ResNet\n",
    "    cr_res_all, cm_res_all = gen_save_cr_cm('res', all_models, original, target, perturbation=test_type, gender=None) # Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e2a5d-09c5-4dcf-9682-d3e030010ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_cr_cm_results(original_folder = \"preprocessing/cv_datasets/\", target_folder = \"cr_cm_results/\"):\n",
    "    \"\"\"\n",
    "    Generates cr_cm_results\n",
    "    \n",
    "    original_folder : str\n",
    "        File path to folder containing original image\n",
    "    target_folder : str\n",
    "        File path to folder to store classification report (CR) and confusion matrix (CM)\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(len(set_nums)), \"Generating results...\"):\n",
    "        set_no = set_nums[i]\n",
    "        original = original_folder + \"set\" + str(set_no) + \"/\"       # Where is it coming from?\n",
    "        target = target_folder + \"set\" + str(set_no) + \"/\"           # Where do you want to store the results?\n",
    "        Path(target).mkdir(parents=True, exist_ok=True)              # Make new directory if empty\n",
    "        all_models = get_all_models(set_no)                          # Grab all models, MobileNet, DenseNet, ResNet50\n",
    "        gen_result_for_sets(all_models, original, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1d340-79a5-4d23-b18a-210127261d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_metrics(model_type, target_folder, perturbation='ori'):\n",
    "    \"\"\"\n",
    "    Loads in results from folder fyp-ma-13/fyp-models/cr_cm_results\n",
    "    \n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    target_folder : str\n",
    "        Target folder name from timeline \n",
    "    perturbation: str\n",
    "        Either 'ori', 'masked', 'glasses', or 'make_up'\n",
    "    \"\"\"\n",
    "    assert perturbation in ['ori', 'masked', 'glasses', 'make_up']\n",
    "    \n",
    "    with open(\"timeline/{}/cr_cm_results/set10/cr_cm_{}_{}_{}\".format(target_folder, model_type, perturbation, 'bothg')) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        data = json.loads(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb16b3-9d98-474f-901f-e31a47201308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gen_cr_cm_results(test_type=\"ori\", original_folder = \"preprocessing/cv_datasets_debiased/\", target_folder = \"cr_cm_results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35c32f-41d1-415a-89ad-ce44a3769e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sum_cm(cm):\n",
    "    \"\"\"\n",
    "    Gets total number of observations of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    res = 0\n",
    "    for i in data_mobile_both['cm_mobile_all']:\n",
    "        res += sum(i)\n",
    "    return res\n",
    "\n",
    "def calculate_acc_cm(cm):\n",
    "    \"\"\"\n",
    "    Gets total accuracy of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    tot = calculate_sum_cm(cm)\n",
    "    tn = cm[0][0]\n",
    "    tp = cm[1][1]\n",
    "    return ((tn+tp)/tot)*100\n",
    "\n",
    "def calculate_female_acc(cm):\n",
    "    \"\"\"\n",
    "    Gets female accuracy of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    female_row = cm[0]\n",
    "    return (female_row[0] / (female_row[0] + female_row[1]))*100\n",
    "    \n",
    "def calculate_male_acc(cm):\n",
    "    \"\"\"\n",
    "    Gets male accuracy of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    male_row = cm[1]\n",
    "    return (male_row[1] / (male_row[0] + male_row[1]))*100\n",
    "\n",
    "def calculate_precision(cm):\n",
    "    \"\"\"\n",
    "    Gets precision of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    return 100*cm[1][1]/(cm[0][1]+cm[1][1])\n",
    "\n",
    "def calculate_recall(cm):\n",
    "    \"\"\"\n",
    "    Gets recall of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    return 100*cm[1][1]/(cm[1][0]+cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34549aa-74a9-4674-9164-a1ccede3c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "data_mobile_both = load_metrics('mobile', debiased_fp)\n",
    "data_dense_both = load_metrics('dense', debiased_fp)\n",
    "data_res_both = load_metrics('res', debiased_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0ff7c-ad21-4ed9-bb61-092fba656925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_stats_graph(data, history, model_type, debiased=False):\n",
    "    \"\"\"\n",
    "    This function does two things:\n",
    "        1. Generate plot showing model statistics and show\n",
    "        2. Saves generated plot∆í\n",
    "        \n",
    "    data : dict\n",
    "        Dictionary containing data on classification report and confusion matrix\n",
    "    history : dict\n",
    "        History of the model\n",
    "    model_type : str\n",
    "        Model type\n",
    "    debiased : boolean\n",
    "        Determines whether we are targetting a debiased or not\n",
    "    \"\"\"\n",
    "    key = f'cm_%s_bothg' % model_type     # Key to access confusion matrix data from \"data\"\n",
    "    \n",
    "    acc = []\n",
    "    val_acc = []\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    acc += history['accuracy']\n",
    "    val_acc += history['val_accuracy']\n",
    "\n",
    "    loss += history['loss']\n",
    "    val_loss += history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplots_adjust(wspace=0.7, hspace= 0.4)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "#   Plot accuracy training/validation graph\n",
    "    plt.subplot(212)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "#   Plot confusion metric values\n",
    "    plt.subplot(222)\n",
    "    cols_barh = ['Male Accuracy', 'Female Accuracy', 'Precision', 'Recall', 'Gender Bias Index']\n",
    "    \n",
    "    \n",
    "    cm = data[key]\n",
    "    m_acc = round(calculate_male_acc(cm), 2)\n",
    "    f_acc = round(calculate_female_acc(cm), 2)\n",
    "    vals_barh = [m_acc, \n",
    "                 f_acc, \n",
    "                 round(calculate_precision(cm), 2),\n",
    "                 round(calculate_recall(cm), 2),\n",
    "                 round(f_acc - m_acc,2)]\n",
    "    \n",
    "    plt.barh(cols_barh, vals_barh)\n",
    "    for index, value in enumerate(vals_barh):\n",
    "        plt.text(value+0.3, index-0.2, str(value), fontweight='bold', ha='left',fontdict=dict(fontsize=12))\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "#   Plot confusion matrix\n",
    "    plt.subplot(221)\n",
    "    kw = key[3:].split('_')\n",
    "    # Update title\n",
    "    f = kw[0]\n",
    "    if f == 'mobile':\n",
    "        kw[0] = \"MobileNet\"\n",
    "    elif f == 'dense':\n",
    "        kw[0] = 'DenseNet'\n",
    "    elif f == 'res':\n",
    "        kw[0] = 'ResNet50'\n",
    "    \n",
    "    if kw[1] == 'all':\n",
    "        kw[1] = 'both'\n",
    "    kw = kw[0]\n",
    "    cf_matrix = np.array(cm)\n",
    "    \n",
    "    group_names = [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "    group_counts = map(round, cf_matrix.flatten())\n",
    "    group_percentages = (\n",
    "        f\"{round(value, 2)}%\" for value in cf_matrix.flatten() / np.sum(cf_matrix)\n",
    "    )\n",
    "    df_cm = pd.DataFrame(cf_matrix, range(2), range(2))\n",
    "    df_cm.index.name = \"Actual\"\n",
    "    df_cm.columns.name = \"Predicted\"\n",
    "    labels = np.asarray([\"\\n\".join(map(str, v)) for v in zip(group_names, group_counts, group_percentages)]).reshape(2, 2)\n",
    "\n",
    "    plt.suptitle(kw, fontsize = 30, ha='center')\n",
    "    \n",
    "    sns.set(font_scale=1.4)  # for label size\n",
    "    sns.heatmap(\n",
    "        df_cm,\n",
    "        annot=labels,\n",
    "        annot_kws={\"size\": 15},\n",
    "        cmap=\"YlOrBr\",\n",
    "        fmt=\"\",\n",
    "        xticklabels=LABELS,\n",
    "        yticklabels=LABELS,\n",
    "    )\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    plt.savefig(f'stats_diagrams/%s_stats_graph.png' % model_type)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6498f53-8750-4d89-b581-d6e9c3cb24b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load histories\n",
    "baseline_fp = \"(5)_early_stopping_20\"\n",
    "debiased_fp = \"(7)_debiased_50\"\n",
    "\n",
    "with open(f'timeline/%s/history/set10/model_tl_history_mobile_set10.json' % baseline_fp) as f:\n",
    "    history_mobile = json.load(f)\n",
    "with open(f'timeline/%s/history/set10/model_tl_history_dense_set10.json' % baseline_fp) as f:\n",
    "    history_dense = json.load(f)\n",
    "with open(f'timeline/%s/history/set10/model_tl_history_res_set10.json' % baseline_fp) as f:\n",
    "    history_res = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b72cb-ce0e-405c-81b5-90254e461d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show statistics for baseline models\n",
    "gen_stats_graph(data_mobile_both, \"cm_mobile_bothg\", history_mobile, 'mobile')                   # Accuracy and Loss graphs for MobileNet\n",
    "gen_stats_graph(data_dense_both, \"cm_dense_bothg\", history_dense, 'dense')                       # Accuracy and Loss graphs for DenseNet\n",
    "gen_stats_graph(data_res_both, \"cm_res_bothg\", history_res, 'res')                               # Accuracy and Loss graphs for ResNet50\n",
    "\n",
    "# Show statistics for debiased models\n",
    "gen_stats_graph(data_mobile_both, \"cm_mobile_bothg\", history_mobile, 'mobile', debiased=True)    # Accuracy and Loss graphs for MobileNet\n",
    "gen_stats_graph(data_dense_both, \"cm_dense_bothg\", history_dense, 'dense', debiased=True)        # Accuracy and Loss graphs for DenseNet\n",
    "gen_stats_graph(data_res_both, \"cm_res_bothg\", history_res, 'res', debiased=True)                # Accuracy and Loss graphs for ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f58494-0899-4633-b469-1fc9a4a8d9de",
   "metadata": {},
   "source": [
    "# Findings\n",
    "- Makeup improves accuracy when predicting females\n",
    "- Glasses improves accuracy when predicting males\n",
    "- Masks generally degrade accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
