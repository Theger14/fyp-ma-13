{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6098bd5-d7f3-45bc-926a-17b4dae25edf",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Import libraries and initialise global variables\n",
    "2. Load data\n",
    "3. Data augmentation\n",
    "4. Load base models\n",
    "5. Model creation using transfer learning\n",
    "    - Base models (from step 4) are used here\n",
    "6. Model training\n",
    "7. Model Analysis\n",
    "    - Get model statistics\n",
    "8. Findings and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759e359-5e06-4600-a633-5a3b7b540734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from gen_results import gen_save_cr_cm # Load test results\n",
    "\n",
    "from tqdm import tqdm            # Progress bar\n",
    "from pathlib import Path         # Create new folder if does not exist\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import json\n",
    "import ssl\n",
    "import time\n",
    "\n",
    "# Set if memory growth should be enabled for a PhysicalDevice.\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19973d36-70ed-4b45-a968-3548751d16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\") # back to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacdefb-605b-498b-a58f-5415fade8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise global variables\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "IMG_SIZE = (224,224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "LABELS = [\"female\", \"male\"]\n",
    "set_nums = [1,5,8,10]            # List of set numbers\n",
    "experiments_folder_1 = \"experiments_20112021\"\n",
    "experiments_folder = \"experiments_12122021\"\n",
    "exp = f'/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/preprocessing/{experiments_folder_1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19f090-19c6-4a37-8283-6a20916a970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV3 Large base model\n",
    "preprocess_input_mobile = tf.keras.applications.mobilenet_v3.preprocess_input\n",
    "base_model_mobile = tf.keras.applications.MobileNetV3Large(\n",
    "    input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "# Load DenseNet 201 base model\n",
    "preprocess_input_dense = tf.keras.applications.densenet.preprocess_input\n",
    "base_model_dense = tf.keras.applications.densenet.DenseNet201(\n",
    "    input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "# Load ResNet50 base model\n",
    "preprocess_input_res = tf.keras.applications.resnet50.preprocess_input\n",
    "base_model_res = tf.keras.applications.resnet50.ResNet50(\n",
    "    input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945efd8-0db2-4841-902a-c155f900513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_val_data(preprocessing_fp):\n",
    "    \"\"\"\n",
    "    Loads in training and validation datasets from a specified file path\n",
    "    \n",
    "    preprocessing_fp : str\n",
    "        File path to load data from (specific set)\n",
    "    \"\"\"\n",
    "    print(f\"loading train and val dataset from{preprocessing_fp}\")\n",
    "    # Load train dataset\n",
    "    train_dataset = image_dataset_from_directory(os.path.join(preprocessing_fp, \"train\"),\n",
    "                                                 shuffle=True,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 image_size=IMG_SIZE)\n",
    "    # Load validation dataset\n",
    "    validation_dataset = image_dataset_from_directory(os.path.join(preprocessing_fp, \"val\"),\n",
    "                                                      shuffle=True,\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      image_size=IMG_SIZE)\n",
    "    \n",
    "    # Data augmentation\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "      tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    ])\n",
    "    return train_dataset, validation_dataset, data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80732b5-5fcb-44fb-bc8e-0cdf50e01ecf",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4084c8-755d-4879-9a56-7ad00c7ac399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base_model, preprocess_input, train_dataset, data_augmentation):\n",
    "    \"\"\"\n",
    "    Creates a new neural network model applying transfer learning.\n",
    "    \n",
    "    base_model : tf.keras.Model\n",
    "        Base model we use for transfer learning\n",
    "    preprocess_input : Function\n",
    "        Function to perform preprocessing of input images for model compatibility\n",
    "    train_dataset : \n",
    "        Training dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Converts images into a 5x5x1280 block of features\n",
    "    image_batch, label_batch = next(iter(train_dataset))\n",
    "    feature_batch = base_model(image_batch)\n",
    "    \n",
    "    # Freeze all convolutional base\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add classification head\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    feature_batch_average = global_average_layer(feature_batch)\n",
    "    \n",
    "    # Model building\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1024, kernel_regularizer='l2', activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1024, kernel_regularizer='l2', activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(512, kernel_regularizer='l2', activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    base_learning_rate = 0.0001\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecd932-a33a-492d-b092-8bf75d7f3b5c",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8a2c9-94f8-465b-a776-9bccc92bdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, set_no, model_type, train_dataset, validation_dataset, male_perc, female_perc, male_pert, female_pert):\n",
    "    \"\"\"\n",
    "    Trains model, and saves model's best weights and history\n",
    "    \n",
    "    model : \n",
    "        Model to train \n",
    "    set_no : int\n",
    "        Set number\n",
    "    model_type : str\n",
    "        Type of model (i.e. 'mobile', 'dense', 'res')\n",
    "    \"\"\"\n",
    "    assert type(male_perc) == float or male_perc == 'ori'\n",
    "    assert type(female_perc) == float or female_perc == 'ori'\n",
    "    male_label = int(male_perc*100) if type(male_perc) == float else male_perc\n",
    "    female_label = int(female_perc*100) if type(female_perc) == float else female_perc\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f\"best_weights/male_{male_label}_{male_pert}_female_{female_label}_{female_pert}/set{set_no}/model_tl_best_weights_{model_type}_set{set_no}.h5\",\n",
    "        monitor=\"loss\",\n",
    "#         verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      mode='min',\n",
    "                                                      patience=5)\n",
    "    \n",
    "    # Save a checkpoint of t/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/preprocessing/experiments_20112021he model for later use\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_dataset,\n",
    "                             epochs=EPOCHS,\n",
    "                             validation_data=validation_dataset,\n",
    "                            callbacks=[checkpoint, early_stopping],\n",
    "#                             verbose=0\n",
    "                       )\n",
    "    time_taken = \"%.2fs\" % (time.time() - start_time)\n",
    "    history.history['time_taken'] = time_taken\n",
    "\n",
    "    \n",
    "    target = f\"history/male_{male_label}_{male_pert}_female_{female_label}_{female_pert}\" # Store model history as a JSON file\n",
    "    Path(target).mkdir(parents=True, exist_ok=True)\n",
    "    with open(os.path.join(target, f\"model_tl_history_{model_type}_set{set_no}.json\"), \"w+\") as f:\n",
    "        json.dump(history.history, f) # Construct the baseline (unperturbed) model\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd140b-c88c-48a2-9d73-1e75ab4e6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_weights_and_history(set_no, male_perc, female_perc, male_pert, female_pert):\n",
    "    \"\"\"\n",
    "    Gets model best weights from training and history\n",
    "    \n",
    "    set_no : int\n",
    "        Set number\n",
    "    \"\"\"\n",
    "    assert type(male_perc) == float or male_perc == 'ori'\n",
    "    assert type(female_perc) == float or female_perc == 'ori'\n",
    "    male_label = int(male_perc*100) if type(male_perc) == float else male_perc\n",
    "    female_label = int(female_perc*100) if type(female_perc) == float else female_perc\n",
    "    preprocessing_fp = f'{exp}/male_{male_label}_{male_pert}_female_{female_label}_{female_pert}/set{set_no}'\n",
    "    train_dataset, validation_dataset, data_aug = load_train_val_data(preprocessing_fp)\n",
    "    # Create the three different models\n",
    "    model_mobile = create_model(base_model_mobile, preprocess_input_mobile, train_dataset, data_aug)\n",
    "    model_dense = create_model(base_model_dense, preprocess_input_dense, train_dataset, data_aug)\n",
    "    model_res = create_model(base_model_res, preprocess_input_res, train_dataset, data_aug)\n",
    "    \n",
    "    history_mobile = model_training(model_mobile,  set_no, 'mobile', \n",
    "                                    train_dataset, validation_dataset, male_perc, female_perc, male_pert, female_pert)\n",
    "    history_dense = model_training(model_dense, set_no, 'dense', \n",
    "                                   train_dataset, validation_dataset, male_perc, female_perc, male_pert, female_pert)\n",
    "    history_res = model_training(model_res, set_no, 'res', \n",
    "                                 train_dataset, validation_dataset, male_perc, female_perc, male_pert, female_pert)\n",
    "    return history_mobile, history_dense, history_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536eecc8-bffc-4426-ac0f-4038c870ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_models_all_sets(male_perc, female_perc, male_pert, female_pert):\n",
    "    \"\"\"\n",
    "    This function does two things:\n",
    "    1. Builds all three mode/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/preprocessing/experiments_20112021l types (MobileNet, ResNet50, DenseNet)\n",
    "    2. Saves model with the best weights and history\n",
    "    \n",
    "    debiased : boolean\n",
    "        Determines whether we are training a debiased model or not\n",
    "    EPOCHS : int\n",
    "        Number of epochs\n",
    "    \"\"\"\n",
    "    for set_no in tqdm(set_nums, \"Loading models...\"):\n",
    "        print(\"Training...\")\n",
    "        print(f\"Male perturbation: {male_pert}, Female perturbation: {female_pert}\")\n",
    "        histories = find_best_weights_and_history(set_no, male_perc, female_perc, male_pert, female_pert)\n",
    "        print(\"Saving...\")\n",
    "        print(\"--------------------------------\")\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d051d1e-1d22-48eb-b081-d49a951a9790",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e6726-c232-406f-b4b8-4a84c240a14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_models(set_no, male_label, female_label, male_pert, female_pert, best_w_fp=\"best_weights/\"):\n",
    "    \"\"\"\n",
    "    Returns a list of Keras models from a specific set \n",
    "    \n",
    "    set_no : int\n",
    "        Set number\n",
    "    best_w_fp : str\n",
    "        File path where the best weights of the models for the particular set is stored\n",
    "    \"\"\"\n",
    "    mf = f'male_{male_label}_{male_pert}_female_{female_label}_{female_pert}'\n",
    "    target = f'{best_w_fp}{mf}/set{set_no}'\n",
    "    mobilenet = tf.keras.models.load_model(f'{target}/model_tl_best_weights_mobile_set{set_no}.h5')\n",
    "    densenet = tf.keras.models.load_model(f'{target}/model_tl_best_weights_dense_set{set_no}.h5')\n",
    "    resnet = tf.keras.models.load_model(f'{target}/model_tl_best_weights_res_set{set_no}.h5')\n",
    "    print(\"best weight path:\", target)\n",
    "    all_models = [mobilenet, densenet, resnet]\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716986e1-392d-4811-bdbe-a8a16432f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_result_for_sets(all_models, original, target, test_pert):\n",
    "    \"\"\"\n",
    "    Call this function to generate Classification Reports and confusion Matrix results\n",
    "    \n",
    "    all_models : list\n",
    "        List of Keras models\n",
    "    original : str\n",
    "        Original file path\n",
    "    target : str\n",
    "        Target file path\n",
    "    \"\"\"\n",
    "    print(f\"original path: {original}, target path: {target}\")\n",
    "    # Classification reports and confusion matrices for MobileNet\n",
    "    cr_mobile_all, cm_mobile_all = gen_save_cr_cm('mobile', all_models, original, target, gender=None, test_pert=test_pert) # Both\n",
    "    # Classification reports and confusion matrices for DenseNet\n",
    "    cr_dense_all, cm_dense_all = gen_save_cr_cm('dense', all_models, original, target, gender=None, test_pert=test_pert) # Both\n",
    "    # Classification reports and confusion matrices for ResNet\n",
    "    cr_res_all, cm_res_all = gen_save_cr_cm('res', all_models, original, target, gender=None, test_pert=test_pert) # Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e2a5d-09c5-4dcf-9682-d3e030010ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_cr_cm_results(male_perc, female_perc, male_pert, female_pert, test_pert, original_folder = \"preprocessing/cv_datasets/\", target_folder = \"cr_cm_results/\"):\n",
    "    \"\"\"\n",
    "    Generates cr_cm_results\n",
    "    \n",
    "    male_perc : float\n",
    "        Percentage of male data to be perturbed\n",
    "    female_perc : float\n",
    "        Percentage of female data to be perturbed\n",
    "    original_folder : str\n",
    "        File path to folder containing original image\n",
    "    target_folder : str\n",
    "        File path to folder to store classification report (CR) and confusion matrix (CM)\n",
    "    \"\"\"\n",
    "    assert type(male_perc) == float or male_perc == 'ori'\n",
    "    assert type(female_perc) == float or female_perc == 'ori'\n",
    "    male_label = int(male_perc*100) if type(male_perc) == float else male_perc\n",
    "    female_label = int(female_perc*100) if type(female_perc) == float else female_perc\n",
    "    target_folder = f\"cr_cm_results/male_{male_label}_{male_pert}_female_{female_label}_{female_pert}/\"\n",
    "    for i in tqdm(range(len(set_nums)), \"Generating results...\"):\n",
    "        set_no = set_nums[i]\n",
    "        original = f'{original_folder}set{set_no}/'                  # Where is it coming from?\n",
    "        target = f'{target_folder}set{set_no}/'                      # Where do you want to store the results?\n",
    "        Path(target).mkdir(parents=True, exist_ok=True)              # Make new directory if empty\n",
    "        all_models = get_all_models(set_no, male_label, female_label, male_pert, female_pert)  # Grab all models, MobileNet, DenseNet, ResNet50\n",
    "        gen_result_for_sets(all_models, original, target, test_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d6a53-9b3a-4980-a044-eaa6a781b4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percs = [0.1, 0.25, 0.5]\n",
    "\n",
    "pert_types = ['glasses', 'makeup', 'masked', 'ori']\n",
    "   \n",
    "# gen_models_all_sets('ori', 'ori', 'ori', 'ori')   \n",
    "for perc in percs:\n",
    "    for t in pert_types:\n",
    "        gen_cr_cm_results(perc, perc, 'glasses', 'makeup', t)\n",
    "\n",
    "#makeup\n",
    "# for perc in percs:\n",
    "#     gen_models_all_sets(perc, perc, 'makeup', 'makeup')\n",
    "#     gen_cr_cm_results(perc, perc, 'makeup', 'makeup')\n",
    "\n",
    "# gen_models_all_sets('ori', 'ori')\n",
    "# gen_cr_cm_results('ori', 'ori')\n",
    "\n",
    "# for male perturbation only\n",
    "# for perc in tqdm(percs, \"Male perturbation only...\"):\n",
    "#     gen_models_all_sets(perc, 'ori')\n",
    "#     gen_cr_cm_results(perc, 'ori')\n",
    "\n",
    "# for female perturbation only\n",
    "# for perc in tqdm(percs, \"Female perturbation only...\"):\n",
    "#     gen_models_all_sets('ori', perc)\n",
    "#     gen_cr_cm_results('ori', perc)\n",
    "\n",
    "# for both\n",
    "# for perc in tqdm(percs, \"Both perturbations...\"):\n",
    "#     gen_models_all_sets(perc, perc)\n",
    "#     gen_cr_cm_results(perc, perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9289519-10ae-40f0-b6d5-537c52a986e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# glasses\n",
    "for perc in percs:\n",
    "    gen_models_all_sets(perc, perc, 'glasses', 'glasses')\n",
    "    gen_cr_cm_results(perc, perc, 'glasses', 'glasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04f53fb-9043-4f88-9996-a73048b15347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_metrics(model_type, target_folder, perturbation='ori'):\n",
    "    \"\"\"\n",
    "    Loads in results from folder fyp-ma-13/fyp-models/cr_cm_results\n",
    "    \n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    target_folder : str\n",
    "        Target folder name from timeline \n",
    "    perturbation: str\n",
    "        Either 'ori', 'masked', 'glasses', or 'make_up'\n",
    "    \"\"\"\n",
    "    assert perturbation in ['ori', 'masked', 'glasses', 'make_up']\n",
    "    \n",
    "    with open(\"timeline/{}/cr_cm_results/set.../cr_cm_{}_{}_{}\".format(target_folder, model_type, perturbation, 'bothg')) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        data = json.loads(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35c32f-41d1-415a-89ad-ce44a3769e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sum_cm(cm):\n",
    "    \"\"\"\n",
    "    Gets total number of observations of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    res = 0\n",
    "    for i in data_mobile_both['cm_mobile_all']:\n",
    "        res += sum(i)\n",
    "    return res\n",
    "\n",
    "def calculate_acc_cm(cm):\n",
    "    \"\"\"\n",
    "    Gets total accuracy of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    tot = calculate_sum_cm(cm)\n",
    "    tn = cm[0][0]\n",
    "    tp = cm[1][1]\n",
    "    return ((tn+tp)/tot)*100\n",
    "\n",
    "def calculate_female_acc(cm):\n",
    "    \"\"\"\n",
    "    Gets female accuracy of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    female_row = cm[0]\n",
    "    return (female_row[0] / (female_row[0] + female_row[1]))*100\n",
    "    \n",
    "def calculate_male_acc(cm):\n",
    "    \"\"\"\n",
    "    Gets male accuracy of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    male_row = cm[1]\n",
    "    return (male_row[1] / (male_row[0] + male_row[1]))*100\n",
    "\n",
    "def calculate_precision(cm):\n",
    "    \"\"\"\n",
    "    Gets precision of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    return 100*cm[1][1]/(cm[0][1]+cm[1][1])\n",
    "\n",
    "def calculate_recall(cm):\n",
    "    \"\"\"\n",
    "    Gets recall of input confusion matrix\n",
    "    \n",
    "    cm : list\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    return 100*cm[1][1]/(cm[1][0]+cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34549aa-74a9-4674-9164-a1ccede3c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "data_mobile_both = load_metrics('mobile', debiased_fp)\n",
    "data_dense_both = load_metrics('dense', debiased_fp)\n",
    "data_res_both = load_metrics('res', debiased_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0ff7c-ad21-4ed9-bb61-092fba656925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_stats_graph(data, history, model_type, debiased=False):\n",
    "    \"\"\"\n",
    "    This function does two things:\n",
    "        1. Generate plot showing model statistics and show\n",
    "        2. Saves generated plotƒ\n",
    "        \n",
    "    data : dict\n",
    "        Dictionary containing data on classification report and confusion matrix\n",
    "    history : dict\n",
    "        History of the model\n",
    "    model_type : str\n",
    "        Model type\n",
    "    debiased : boolean\n",
    "        Determines whether we are targetting a debiased or not\n",
    "    \"\"\"\n",
    "    key = f'cm_%s_bothg' % model_type     # Key to access confusion matrix data from \"data\"\n",
    "    \n",
    "    acc = []\n",
    "    val_acc = []\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    acc += history['accuracy']\n",
    "    val_acc += history['val_accuracy']\n",
    "\n",
    "    loss += history['loss']\n",
    "    val_loss += history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplots_adjust(wspace=0.7, hspace= 0.4)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "#   Plot accuracy training/validation graph\n",
    "    plt.subplot(212)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "#   Plot confusion metric values\n",
    "    plt.subplot(222)\n",
    "    cols_barh = ['Male Accuracy', 'Female Accuracy', 'Precision', 'Recall', 'Gender Bias Index']\n",
    "    \n",
    "    \n",
    "    cm = data[key]\n",
    "    m_acc = round(calculate_male_acc(cm), 2)\n",
    "    f_acc = round(calculate_female_acc(cm), 2)\n",
    "    vals_barh = [m_acc, \n",
    "                 f_acc, \n",
    "                 round(calculate_precision(cm), 2),\n",
    "                 round(calculate_recall(cm), 2),\n",
    "                 round(f_acc - m_acc,2)]\n",
    "    \n",
    "    plt.barh(cols_barh, vals_barh)\n",
    "    for index, value in enumerate(vals_barh):\n",
    "        plt.text(value+0.3, index-0.2, str(value), fontweight='bold', ha='left',fontdict=dict(fontsize=12))\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "#   Plot confusion matrix\n",
    "    plt.subplot(221)\n",
    "    kw = key[3:].split('_')\n",
    "    # Update title\n",
    "    f = kw[0]\n",
    "    if f == 'mobile':\n",
    "        kw[0] = \"MobileNet\"\n",
    "    elif f == 'dense':\n",
    "        kw[0] = 'DenseNet'\n",
    "    elif f == 'res':\n",
    "        kw[0] = 'ResNet50'\n",
    "    \n",
    "    if kw[1] == 'all':\n",
    "        kw[1] = 'both'\n",
    "    kw = kw[0]\n",
    "    cf_matrix = np.array(cm)\n",
    "    \n",
    "    group_names = [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "    group_counts = map(round, cf_matrix.flatten())\n",
    "    group_percentages = (\n",
    "        f\"{round(value, 2)}%\" for value in cf_matrix.flatten() / np.sum(cf_matrix)\n",
    "    )\n",
    "    df_cm = pd.DataFrame(cf_matrix, range(2), range(2))\n",
    "    df_cm.index.name = \"Actual\"\n",
    "    df_cm.columns.name = \"Predicted\"\n",
    "    labels = np.asarray([\"\\n\".join(map(str, v)) for v in zip(group_names, group_counts, group_percentages)]).reshape(2, 2)\n",
    "\n",
    "    plt.suptitle(kw, fontsize = 30, ha='center')\n",
    "    \n",
    "    sns.set(font_scale=1.4)  # for label size\n",
    "    sns.heatmap(\n",
    "        df_cm,\n",
    "        annot=labels,\n",
    "        annot_kws={\"size\": 15},\n",
    "        cmap=\"YlOrBr\",\n",
    "        fmt=\"\",\n",
    "        xticklabels=LABELS,\n",
    "        yticklabels=LABELS,\n",
    "    )\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    plt.savefig(f'stats_diagrams/%s_stats_graph.png' % model_type)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6498f53-8750-4d89-b581-d6e9c3cb24b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load histories\n",
    "baseline_fp = \"(5)_early_stopping_20\"\n",
    "debiased_fp = \"(7)_debiased_50\"\n",
    "\n",
    "with open(f'timeline/%s/history/set10/model_tl_history_mobile_set10.json' % baseline_fp) as f:\n",
    "    history_mobile = json.load(f)\n",
    "with open(f'timeline/%s/history/set10/model_tl_history_dense_set10.json' % baseline_fp) as f:\n",
    "    history_dense = json.load(f)\n",
    "with open(f'timeline/%s/history/set10/model_tl_history_res_set10.json' % baseline_fp) as f:\n",
    "    history_res = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b72cb-ce0e-405c-81b5-90254e461d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show statistics for baseline models\n",
    "gen_stats_graph(data_mobile_both, \"cm_mobile_bothg\", history_mobile, 'mobile')                   # Accuracy and Loss graphs for MobileNet\n",
    "gen_stats_graph(data_dense_both, \"cm_dense_bothg\", history_dense, 'dense')                       # Accuracy and Loss graphs for DenseNet\n",
    "gen_stats_graph(data_res_both, \"cm_res_bothg\", history_res, 'res')                               # Accuracy and Loss graphs for ResNet50\n",
    "\n",
    "# Show statistics for debiased models\n",
    "gen_stats_graph(data_mobile_both, \"cm_mobile_bothg\", history_mobile, 'mobile', debiased=True)    # Accuracy and Loss graphs for MobileNet\n",
    "gen_stats_graph(data_dense_both, \"cm_dense_bothg\", history_dense, 'dense', debiased=True)        # Accuracy and Loss graphs for DenseNet\n",
    "gen_stats_graph(data_res_both, \"cm_res_bothg\", history_res, 'res', debiased=True)                # Accuracy and Loss graphs for ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f58494-0899-4633-b469-1fc9a4a8d9de",
   "metadata": {},
   "source": [
    "# Findings\n",
    "- Makeup improves accuracy when predicting females\n",
    "- Glasses improves accuracy when predicting males\n",
    "- Masks generally degrade accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
