{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5b61b-f303-4f63-bbd8-5f9b372aa1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16f73ad-73c2-40a4-b1ad-4af766cd2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# from gen_results import gen_save_cr_cm # Load test results\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import ssl\n",
    "import time\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe54ee1-90a3-4162-a5d1-710a1ce3f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global preprocessing_fp\n",
    "global train_dataset\n",
    "global validation_dataset\n",
    "global data_augmentation\n",
    "\n",
    "global EPOCHS\n",
    "global flag # Tracks whether base_models where initialised\n",
    "flag = False\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE # Use buffered prefetching to load images without having I/O blocking\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = (224,224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "LABELS = [\"female\", \"male\"]\n",
    "\n",
    "# Load base models\n",
    "global preprocess_input_mobile, base_model_mobile\n",
    "global preprocess_input_dense, base_model_dense\n",
    "global preprocess_input_res, base_model_res\n",
    "\n",
    "# Generate models\n",
    "global model_mobile\n",
    "global model_dense\n",
    "global model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd3a3c3-1c2c-4336-aeed-51bacffef67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_preprocessing_fp(target):\n",
    "    global preprocessing_fp \n",
    "    preprocessing_fp = target\n",
    "    \n",
    "def set_epochs(epochs=50):\n",
    "    global EPOCHS\n",
    "    EPOCHS = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31621702-a480-4e95-9a98-15d37ab40600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_val():\n",
    "    global train_dataset\n",
    "    global validation_dataset\n",
    "    \n",
    "    # Load train dataset\n",
    "    train_dataset = image_dataset_from_directory(os.path.join(preprocessing_fp, \"train\"),\n",
    "                                                 shuffle=True,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 image_size=IMG_SIZE)\n",
    "\n",
    "    # Load validation dataset\n",
    "    validation_dataset = image_dataset_from_directory(os.path.join(preprocessing_fp, \"val\"),\n",
    "                                                      shuffle=True,\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3dc5576-3f02-48e0-b500-bcf8a6449742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prefetch_augmentation():\n",
    "    global train_dataset\n",
    "    global validation_dataset\n",
    "    global data_augmentation \n",
    "    \n",
    "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    # Helpful since we want to expand our image dataset\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "      tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b514f2-9589-4047-b31f-d9272dbf58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_models(IMG_SHAPE=IMG_SHAPE):\n",
    "    global preprocess_input_mobile, base_model_mobile\n",
    "    global preprocess_input_dense, base_model_dense\n",
    "    global preprocess_input_res, base_model_res\n",
    "    \n",
    "    # Load MobileNetV3 Large\n",
    "    preprocess_input_mobile = tf.keras.applications.mobilenet_v3.preprocess_input\n",
    "    base_model_mobile = tf.keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "    # Load DenseNet 201\n",
    "    preprocess_input_dense = tf.keras.applications.densenet.preprocess_input\n",
    "    base_model_dense = tf.keras.applications.densenet.DenseNet201(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "    # Load ResNet50\n",
    "    preprocess_input_res = tf.keras.applications.resnet50.preprocess_input\n",
    "    base_model_res = tf.keras.applications.resnet50.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23487e52-e5e5-4693-a731-41567be40307",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12a02c44-6b0d-4a57-848c-c5d08cc1cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base_model, preprocess_input):\n",
    "    global train_dataset\n",
    "    \n",
    "    # Converts images into a 5x5x1280 block of features\n",
    "    image_batch, label_batch = next(iter(train_dataset))\n",
    "    feature_batch = base_model(image_batch)\n",
    "    \n",
    "    # Freeze all convolutional base\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add classification head\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    feature_batch_average = global_average_layer(feature_batch)\n",
    "    \n",
    "    # Model building\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1024, kernel_regularizer='l2', activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1024, kernel_regularizer='l2', activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(512, kernel_regularizer='l2', activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    base_learning_rate = 0.0001\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e2c904-6b1c-4f90-9ccb-2af11a1f58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_models():\n",
    "    global model_mobile\n",
    "    global model_dense\n",
    "    global model_res\n",
    "    global base_model_mobile, preprocess_input_mobile\n",
    "    global base_model_dense, preprocess_input_dense\n",
    "    global base_model_res, preprocess_input_res\n",
    "    \n",
    "    # Create the three different models\n",
    "    model_mobile = create_model(base_model_mobile, preprocess_input_mobile)\n",
    "    model_dense = create_model(base_model_dense, preprocess_input_dense)\n",
    "    model_res = create_model(base_model_res, preprocess_input_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400791e7-2afc-45d4-bd6d-01a11a957a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_training(model, set_no, suffix):\n",
    "    \"\"\"\n",
    "    Trains model, and saves model's best weights and history\n",
    "    \n",
    "    set_no: int\n",
    "        set number\n",
    "    \"\"\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"best_weights/set{}/model_tl_best_weights_{}_set{}.h5\".format(set_no, suffix, set_no),\n",
    "        monitor=\"loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=5,\n",
    "                                                     mode='max')\n",
    "    \n",
    "    # Save a checkpoint of the model for later use\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_dataset,\n",
    "                             epochs=EPOCHS,\n",
    "                             validation_data=validation_dataset,\n",
    "                            callbacks=[checkpoint, early_stopping])\n",
    "    time_taken = \"%.2fs\" % (time.time() - start_time)\n",
    "    history.history['time_taken'] = time_taken\n",
    "\n",
    "    # Store model history as a JSON file\n",
    "    target = \"history/set{}\".format(str(set_no))\n",
    "    with open(os.path.join(target, \"model_tl_history_{}_set{}.json\".format(suffix, set_no)), \"w\") as f:\n",
    "        json.dump(history.history, f) # Construct the baseline (unperturbed) model\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47499046-2a0e-4bf0-bb91-1755d7ba6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(target, epochs=EPOCHS):\n",
    "    \"\"\"\n",
    "    Initialises or resets datasets according to target path\n",
    "    \n",
    "    \"\"\"\n",
    "    global flag\n",
    "    \n",
    "    print(\"Setting preprocessing_fp...\")\n",
    "    set_preprocessing_fp(target)\n",
    "    print(\"Setting number of epochs...\")\n",
    "    set_epochs(epochs)\n",
    "    print(\"Loading train and validation data...\")\n",
    "    load_train_val()\n",
    "    if not flag:\n",
    "        print(\"Loading prefetch and data augmentation variable initialised...\")\n",
    "        data_prefetch_augmentation()\n",
    "        print(\"Loading base models...\")\n",
    "        load_base_models()\n",
    "        flag = True\n",
    "        print(\"Flag set to:\", flag)\n",
    "    print(\"Generating models...\")\n",
    "    gen_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b4515-657b-4992-a15e-1d61ef5c6f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train each of the models\n",
    "def find_best_weights_and_history(set_no):\n",
    "    \"\"\"\n",
    "    Gets model best weights from training and history\n",
    "    \n",
    "    \"\"\"\n",
    "    history_mobile = model_training(model_mobile,  set_no, 'mobile')\n",
    "    history_dense = model_training(model_dense, set_no, 'dense')\n",
    "    history_res = model_training(model_res, set_no, 'res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c8117-ee93-44a8-94dc-151189f14072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b009978-ce1e-43f3-850e-66f10de2412d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
