{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf1ad25-1567-4016-ba5a-baf0b971e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1156ad-07fc-441c-8d9f-6e39b326252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_fp = \"preprocessing/combined_filtered/\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "IMG_SIZE = (224,224)\n",
    "LABELS = [\"female\", \"male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b1ef4c9-db86-42be-bb1d-e1ee0b2681b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = tf.keras.models.load_model('model_tl_best_weights_mobile.h5')\n",
    "densenet = tf.keras.models.load_model('model_tl_best_weights_dense.h5')\n",
    "resnet = tf.keras.models.load_model('model_tl_best_weights_res.h5')\n",
    "all_models = [mobilenet, densenet, resnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb2a0d8c-547a-4f25-bdd9-d4088437cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(model_type, gender=None, models=all_models):\n",
    "    \"\"\"\n",
    "    Returns classification report and confusion matrix (sklearn.metrics)\n",
    "    \n",
    "    model_type : str\n",
    "        Either mobile, dense or res\n",
    "    gender : str\n",
    "        Either None, male or female to specify the gender. If None it make predictions on both.\n",
    "    \"\"\"\n",
    "    # FEMALE => 0\n",
    "    # MALE => 1\n",
    "    \n",
    "    # Set model\n",
    "    if (model_type == \"mobile\"):\n",
    "        model = all_models[0]\n",
    "    elif (model_type == \"dense\"):\n",
    "        model = all_models[1]\n",
    "    elif (model_type == \"res\"):\n",
    "        model = all_models[2]\n",
    "    else:\n",
    "        raise Exception(\"Sorry, model_type allowed are 'mobile' (MobileNet), 'dense' (DenseNet) \\\n",
    "        or 'res' (ResNet50)\")\n",
    "    \n",
    "    assert gender in [None, 'male', 'female'], \"gender needs to be 'male' or 'female'\"\n",
    "    \n",
    "    datasets = [\"test_ori\", \"test_masked\", \"test_glasses\", \"test_make_up\"]\n",
    "    for i in tqdm(range(len(datasets)), 'Loading test datasets...'):\n",
    "        data_name = datasets[i]\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        male_dir = os.listdir(preprocessing_fp + data_name + \"/male\")\n",
    "        female_dir = os.listdir(preprocessing_fp + data_name + \"/female\")\n",
    "        \n",
    "        if gender is None:\n",
    "            for i in tqdm(range(len(male_dir))):\n",
    "                fn = male_dir[i]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/male/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(1)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "\n",
    "            for i in tqdm(range(len(female_dir))):\n",
    "                fn = female_dir[i]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/female/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(0)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "        elif gender == 'male':\n",
    "            for i in tqdm(range(len(male_dir))):\n",
    "                fn = male_dir[i]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/male/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(1)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "        elif gender == 'female':\n",
    "            for i in tqdm(range(len(female_dir))):\n",
    "                fn = female_dir[i]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/female/\" + i)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(0)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "\n",
    "        cr = classification_report(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        return cr, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b2190-70f4-45e2-9411-f401b5a47635",
   "metadata": {},
   "source": [
    "# Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0628de46-2ef4-4be7-8bb7-3c142ff4e7e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      2144\n",
      "           1       0.79      0.76      0.78      1860\n",
      "\n",
      "    accuracy                           0.80      4004\n",
      "   macro avg       0.80      0.80      0.80      4004\n",
      "weighted avg       0.80      0.80      0.80      4004\n",
      "\n",
      "\n",
      "[[1774  370]\n",
      " [ 438 1422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63      2144\n",
      "           1       0.59      0.66      0.62      1862\n",
      "\n",
      "    accuracy                           0.63      4006\n",
      "   macro avg       0.63      0.63      0.63      4006\n",
      "weighted avg       0.63      0.63      0.63      4006\n",
      "\n",
      "\n",
      "[[1284  860]\n",
      " [ 636 1226]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.61      0.69      2144\n",
      "           1       0.64      0.80      0.71      1860\n",
      "\n",
      "    accuracy                           0.70      4004\n",
      "   macro avg       0.71      0.71      0.70      4004\n",
      "weighted avg       0.72      0.70      0.70      4004\n",
      "\n",
      "\n",
      "[[1316  828]\n",
      " [ 367 1493]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.94      0.78      2144\n",
      "           1       0.87      0.46      0.60      1860\n",
      "\n",
      "    accuracy                           0.72      4004\n",
      "   macro avg       0.77      0.70      0.69      4004\n",
      "weighted avg       0.76      0.72      0.70      4004\n",
      "\n",
      "\n",
      "[[2019  125]\n",
      " [1011  849]]\n",
      "\n",
      " ================================================= \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      2144\n",
      "           1       0.85      0.81      0.83      1860\n",
      "\n",
      "    accuracy                           0.84      4004\n",
      "   macro avg       0.84      0.84      0.84      4004\n",
      "weighted avg       0.84      0.84      0.84      4004\n",
      "\n",
      "\n",
      "[[1874  270]\n",
      " [ 358 1502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.39      0.52      2144\n",
      "           1       0.55      0.86      0.67      1862\n",
      "\n",
      "    accuracy                           0.61      4006\n",
      "   macro avg       0.66      0.63      0.59      4006\n",
      "weighted avg       0.66      0.61      0.59      4006\n",
      "\n",
      "\n",
      "[[ 834 1310]\n",
      " [ 258 1604]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72      2144\n",
      "           1       0.67      0.79      0.73      1860\n",
      "\n",
      "    accuracy                           0.72      4004\n",
      "   macro avg       0.73      0.73      0.72      4004\n",
      "weighted avg       0.73      0.72      0.72      4004\n",
      "\n",
      "\n",
      "[[1414  730]\n",
      " [ 382 1478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79      2144\n",
      "           1       0.88      0.48      0.62      1860\n",
      "\n",
      "    accuracy                           0.73      4004\n",
      "   macro avg       0.78      0.71      0.71      4004\n",
      "weighted avg       0.77      0.73      0.71      4004\n",
      "\n",
      "\n",
      "[[2021  123]\n",
      " [ 959  901]]\n",
      "\n",
      " ================================================= \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      2144\n",
      "           1       0.81      0.85      0.83      1860\n",
      "\n",
      "    accuracy                           0.84      4004\n",
      "   macro avg       0.84      0.84      0.84      4004\n",
      "weighted avg       0.84      0.84      0.84      4004\n",
      "\n",
      "\n",
      "[[1783  361]\n",
      " [ 272 1588]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65      2144\n",
      "           1       0.60      0.68      0.64      1862\n",
      "\n",
      "    accuracy                           0.64      4006\n",
      "   macro avg       0.65      0.65      0.64      4006\n",
      "weighted avg       0.65      0.64      0.65      4006\n",
      "\n",
      "\n",
      "[[1312  832]\n",
      " [ 591 1271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79      2144\n",
      "           1       0.81      0.58      0.68      1860\n",
      "\n",
      "    accuracy                           0.74      4004\n",
      "   macro avg       0.76      0.73      0.73      4004\n",
      "weighted avg       0.76      0.74      0.74      4004\n",
      "\n",
      "\n",
      "[[1890  254]\n",
      " [ 774 1086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.95      0.80      2144\n",
      "           1       0.90      0.51      0.65      1860\n",
      "\n",
      "    accuracy                           0.74      4004\n",
      "   macro avg       0.79      0.73      0.72      4004\n",
      "weighted avg       0.79      0.74      0.73      4004\n",
      "\n",
      "\n",
      "[[2034  110]\n",
      " [ 912  948]]\n",
      "\n",
      " ================================================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for model in models:\n",
    "#     make_preds(model)\n",
    "#     print(\"\\n ================================================= \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99de50b-9724-414c-9343-2ccdfc87e7f7",
   "metadata": {},
   "source": [
    "# Male only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d8ace32-228c-4e3a-b7f5-3ca9095a6b2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.76      0.87      1860\n",
      "\n",
      "    accuracy                           0.76      1860\n",
      "   macro avg       0.50      0.38      0.43      1860\n",
      "weighted avg       1.00      0.76      0.87      1860\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 438 1422]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.66      0.79      1862\n",
      "\n",
      "    accuracy                           0.66      1862\n",
      "   macro avg       0.50      0.33      0.40      1862\n",
      "weighted avg       1.00      0.66      0.79      1862\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 636 1226]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.80      0.89      1860\n",
      "\n",
      "    accuracy                           0.80      1860\n",
      "   macro avg       0.50      0.40      0.45      1860\n",
      "weighted avg       1.00      0.80      0.89      1860\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 367 1493]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.46      0.63      1860\n",
      "\n",
      "    accuracy                           0.46      1860\n",
      "   macro avg       0.50      0.23      0.31      1860\n",
      "weighted avg       1.00      0.46      0.63      1860\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [1011  849]]\n",
      "\n",
      " ================================================= \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.81      0.89      1860\n",
      "\n",
      "    accuracy                           0.81      1860\n",
      "   macro avg       0.50      0.40      0.45      1860\n",
      "weighted avg       1.00      0.81      0.89      1860\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 358 1502]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.86      0.93      1862\n",
      "\n",
      "    accuracy                           0.86      1862\n",
      "   macro avg       0.50      0.43      0.46      1862\n",
      "weighted avg       1.00      0.86      0.93      1862\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 258 1604]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.79      0.89      1860\n",
      "\n",
      "    accuracy                           0.79      1860\n",
      "   macro avg       0.50      0.40      0.44      1860\n",
      "weighted avg       1.00      0.79      0.89      1860\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 382 1478]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.48      0.65      1860\n",
      "\n",
      "    accuracy                           0.48      1860\n",
      "   macro avg       0.50      0.24      0.33      1860\n",
      "weighted avg       1.00      0.48      0.65      1860\n",
      "\n",
      "\n",
      "[[  0   0]\n",
      " [959 901]]\n",
      "\n",
      " ================================================= \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.85      0.92      1860\n",
      "\n",
      "    accuracy                           0.85      1860\n",
      "   macro avg       0.50      0.43      0.46      1860\n",
      "weighted avg       1.00      0.85      0.92      1860\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 272 1588]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.68      0.81      1862\n",
      "\n",
      "    accuracy                           0.68      1862\n",
      "   macro avg       0.50      0.34      0.41      1862\n",
      "weighted avg       1.00      0.68      0.81      1862\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 591 1271]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.58      0.74      1860\n",
      "\n",
      "    accuracy                           0.58      1860\n",
      "   macro avg       0.50      0.29      0.37      1860\n",
      "weighted avg       1.00      0.58      0.74      1860\n",
      "\n",
      "\n",
      "[[   0    0]\n",
      " [ 774 1086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.51      0.68      1860\n",
      "\n",
      "    accuracy                           0.51      1860\n",
      "   macro avg       0.50      0.25      0.34      1860\n",
      "weighted avg       1.00      0.51      0.68      1860\n",
      "\n",
      "\n",
      "[[  0   0]\n",
      " [912 948]]\n",
      "\n",
      " ================================================= \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# for model in models:\n",
    "#     make_preds(model, 'male')\n",
    "#     print(\"\\n ================================================= \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ded243-707f-4ffd-a6a7-935c121035e8",
   "metadata": {},
   "source": [
    "# Female only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84362b5a-6c75-4d73-8f54-fdb8bab25010",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83      2144\n",
      "   macro avg       0.50      0.41      0.45      2144\n",
      "weighted avg       1.00      0.83      0.91      2144\n",
      "\n",
      "\n",
      "[[1774  370]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60      2144\n",
      "   macro avg       0.50      0.30      0.37      2144\n",
      "weighted avg       1.00      0.60      0.75      2144\n",
      "\n",
      "\n",
      "[[1284  860]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61      2144\n",
      "   macro avg       0.50      0.31      0.38      2144\n",
      "weighted avg       1.00      0.61      0.76      2144\n",
      "\n",
      "\n",
      "[[1316  828]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94      2144\n",
      "   macro avg       0.50      0.47      0.48      2144\n",
      "weighted avg       1.00      0.94      0.97      2144\n",
      "\n",
      "\n",
      "[[2019  125]\n",
      " [   0    0]]\n",
      "\n",
      " ================================================= \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87      2144\n",
      "   macro avg       0.50      0.44      0.47      2144\n",
      "weighted avg       1.00      0.87      0.93      2144\n",
      "\n",
      "\n",
      "[[1874  270]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.39      0.56      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39      2144\n",
      "   macro avg       0.50      0.19      0.28      2144\n",
      "weighted avg       1.00      0.39      0.56      2144\n",
      "\n",
      "\n",
      "[[ 834 1310]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.66      0.79      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66      2144\n",
      "   macro avg       0.50      0.33      0.40      2144\n",
      "weighted avg       1.00      0.66      0.79      2144\n",
      "\n",
      "\n",
      "[[1414  730]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94      2144\n",
      "   macro avg       0.50      0.47      0.49      2144\n",
      "weighted avg       1.00      0.94      0.97      2144\n",
      "\n",
      "\n",
      "[[2021  123]\n",
      " [   0    0]]\n",
      "\n",
      " ================================================= \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83      2144\n",
      "   macro avg       0.50      0.42      0.45      2144\n",
      "weighted avg       1.00      0.83      0.91      2144\n",
      "\n",
      "\n",
      "[[1783  361]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61      2144\n",
      "   macro avg       0.50      0.31      0.38      2144\n",
      "weighted avg       1.00      0.61      0.76      2144\n",
      "\n",
      "\n",
      "[[1312  832]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      2144\n",
      "   macro avg       0.50      0.44      0.47      2144\n",
      "weighted avg       1.00      0.88      0.94      2144\n",
      "\n",
      "\n",
      "[[1890  254]\n",
      " [   0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      2144\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95      2144\n",
      "   macro avg       0.50      0.47      0.49      2144\n",
      "weighted avg       1.00      0.95      0.97      2144\n",
      "\n",
      "\n",
      "[[2034  110]\n",
      " [   0    0]]\n",
      "\n",
      " ================================================= \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/monash/.pyenv/versions/3.6.13/envs/fyp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# for model in models:\n",
    "#     make_preds(model, 'female')\n",
    "#     print(\"\\n ================================================= \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
