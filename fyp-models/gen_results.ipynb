{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb14905-e4ff-4125-aa27-82fda442555a",
   "metadata": {},
   "source": [
    "### This script contains:\n",
    "- gen_metrics() : Returns classification report and confusion matrix (sklearn.metrics)\n",
    "- gen_save_cr_cm() : Generates, saves and returns classification reports and confusion matrix\n",
    "- make_pred() : Returns predicted class and confidence for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf1ad25-1567-4016-ba5a-baf0b971e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66be95f7-58ed-45ee-b758-4af8f0ca7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b1156ad-07fc-441c-8d9f-6e39b326252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "IMG_SIZE = (224,224)\n",
    "LABELS = [\"female\", \"male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2a0d8c-547a-4f25-bdd9-d4088437cd91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_metrics(model_type, all_models, original_fp, perturbation='all', gender=None):\n",
    "    \"\"\"\n",
    "    Returns classification report and confusion matrix (sklearn.metrics)\n",
    "    \n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    all_models : list\n",
    "        List of models i.e. [mobilenet, densenet, resnet]\n",
    "    original_fp : str\n",
    "        Original image file path\n",
    "    perturbation: str\n",
    "        Perturbation type. Either 'ori', 'masked', 'glasses', 'make_up' or 'all'\n",
    "    gender : str\n",
    "        Gender. Either None, 'male' or female to specify the gender. If None it make predictions on both.\n",
    "    \"\"\"\n",
    "    # FEMALE => 0\n",
    "    # MALE => 1\n",
    "    \n",
    "    # Set model\n",
    "    if (model_type == \"mobile\"):\n",
    "        model = all_models[0]\n",
    "    elif (model_type == \"dense\"):\n",
    "        model = all_models[1]\n",
    "    elif (model_type == \"res\"):\n",
    "        model = all_models[2]\n",
    "    else:\n",
    "        raise Exception(\"Sorry, model_type allowed are 'mobile' (MobileNet), 'dense' (DenseNet) \\\n",
    "        or 'res' (ResNet50)\")\n",
    "    assert gender in [None, 'male', 'female'], \"gender needs to be None, 'male' or 'female'\"\n",
    "    \n",
    "    datasets = [\"test\", \"test_masked\", \"test_glasses\", \"test_makeup\"]\n",
    "    # If we only want ont type of perturbation\n",
    "    if perturbation != 'all':\n",
    "        assert perturbation in ['ori', 'masked', 'glasses', 'makeup']\n",
    "        if perturbation == 'ori':\n",
    "            datasets = [\"test\"]\n",
    "        else:\n",
    "            datasets = [\"test_\"+perturbation]\n",
    "    \n",
    "    for i in tqdm(range(len(datasets)), 'Testing...'):\n",
    "        data_name = datasets[i]\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        male_dir = os.listdir(original_fp + data_name + \"/male\")\n",
    "        female_dir = os.listdir(original_fp + data_name + \"/female\")\n",
    "        \n",
    "        if gender is None:\n",
    "            for j in range(len(male_dir)):\n",
    "                fn = male_dir[j]\n",
    "                img = Image.open(original_fp + data_name + \"/male/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(1)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "\n",
    "            for k in range(len(female_dir)):\n",
    "                fn = female_dir[k]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/female/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(0)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "        elif gender == 'male':\n",
    "            for j in range(len(male_dir)):\n",
    "                fn = male_dir[j]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/male/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(1)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "        elif gender == 'female':\n",
    "            for k in range(len(female_dir)):\n",
    "                fn = female_dir[k]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/female/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(0)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "\n",
    "        cr = classification_report(y_true, y_pred, zero_division = 1)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "    return cr, cm\n",
    "\n",
    "def gen_save_cr_cm(model_type, all_models, original_fp, target_fp, perturbation='all', gender=None):\n",
    "    \"\"\"\n",
    "    Generates, saves and returns classification reports and confusion matrix\n",
    "    \n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    all_models : list\n",
    "        List of models i.e. [mobilenet, densenet, resnet]\n",
    "    original_fp : str\n",
    "        Original image file path\n",
    "    target_fp : str\n",
    "        Target file path to save results\n",
    "    perturbation: str\n",
    "        Either 'ori', 'masked', 'glasses', 'make_up' or 'all'\n",
    "    gender : str\n",
    "        Either None, 'male' or female to specify the gender. If None it make predictions on both.\n",
    "    \"\"\"\n",
    "    assert model_type in ['mobile', 'dense', 'res'], 'Incorrect model_type param value'\n",
    "    assert gender in [None, 'male', 'female'], 'Incorrect gender param value'\n",
    "    \n",
    "    # Assign to appropriate folder\n",
    "    if perturbation != 'all':\n",
    "        assert perturbation in ['ori', 'masked', 'glasses', 'makeup']\n",
    "    \n",
    "    # @TODO: Solve this inefficient checking of gender\n",
    "    temp = gender\n",
    "    if temp is None: # Checks if it is for all genders\n",
    "        temp = 'bothg'\n",
    "    x = target_fp+'cr_cm_{}_{}_{}'.format(model_type, perturbation, temp)\n",
    "    if path.exists(x):    # if it already exists\n",
    "        print(x + \" already exists, pass\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(\"Creating \" + x +\"...\")\n",
    "\n",
    "    cr, cm = gen_metrics(model_type, all_models, original_fp, perturbation, gender=gender)\n",
    "    \n",
    "    # If we only want one type of perturbation\n",
    "    if gender == None:\n",
    "        gender = 'bothg'\n",
    "    # Dumps metrics into a JSON object\n",
    "    res = {\"cr_{}_{}\".format(model_type, gender): cr, \n",
    "           \"cm_{}_{}\".format(model_type, gender): cm.tolist()}\n",
    "    j = json.dumps(res, indent = 4)\n",
    "    \n",
    "    # Save as JSON object\n",
    "    fn = Path(target_fp+'cr_cm_{}_{}_{}'.format(model_type, perturbation, gender))\n",
    "    if not fn.is_dir():\n",
    "        with open(target_fp+'cr_cm_{}_{}_{}'.format(model_type, perturbation, gender), 'w') as outfile:\n",
    "            json.dump(j, outfile)\n",
    "    return cr, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc4a9a-2d43-47e4-9699-d3458816987f",
   "metadata": {},
   "source": [
    "# Make individual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85142669-a090-4014-abda-f4574faf482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3084aaeb-c2d4-4c9b-84ef-2e54d3eff820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in glasses filter module\n",
    "glasses_mod = imp.load_source('apply_glasses', 'preprocessing/perturb_filters/glasses/put_glasses.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bdf65a-3a90-4b31-a553-2d8d9b0b01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation functions\n",
    "# @TODO: Implement perturbation functions\n",
    "# Each function temporarily saves the perturbed images\n",
    "def apply_mask():\n",
    "    return\n",
    "    \n",
    "def apply_glasses(original_fp, target_fp):\n",
    "    spl = original_fp.split(\"/\")\n",
    "    try:\n",
    "        # Call apply_glasses from the glasses module\n",
    "        glasses_mod.apply_glasses('/'.join(spl[:-1]), spl[-1], '')\n",
    "        print(\"Success!\")\n",
    "    except Exception as e:\n",
    "        print(\"Please try Again.\")\n",
    "        print(e)\n",
    "    \n",
    "def apply_makeup():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c4a7f9-b22f-47dc-bd38-6b872f358afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "apply_glasses(\"tom.jpg\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b1ef4c9-db86-42be-bb1d-e1ee0b2681b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet = tf.keras.models.load_model('model_tl_best_weights_mobile.h5')\n",
    "# densenet = tf.keras.models.load_model('model_tl_best_weights_dense.h5')\n",
    "# resnet = tf.keras.models.load_model('model_tl_best_weights_res.h5')\n",
    "# all_models = [mobilenet, densenet, resnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b53d15-e0ec-4c2d-b04a-6d49c3995951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(image_fn, model_type, pt=None):\n",
    "    \"\"\"\n",
    "    Returns predicted class and confidence for a single image\n",
    "    image_fn : str\n",
    "        Path to image\n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    pt : str\n",
    "        Perturbation type (default = None)\n",
    "    \"\"\"\n",
    "    # Set model\n",
    "    if (model_type == \"mobile\"):\n",
    "        model = tf.keras.models.load_model('/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/timeline/(8)_debiased_25/best_weights/set10/model_tl_best_weights_mobile_set10.h5')\n",
    "    elif (model_type == \"dense\"):\n",
    "        model = tf.keras.models.load_model('/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/timeline/(8)_debiased_25/best_weights/set10/model_tl_best_weights_dense_set10.h5')\n",
    "    elif (model_type == \"res\"):\n",
    "        model = tf.keras.models.load_model('/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/timeline/(8)_debiased_25/best_weights/set10/model_tl_best_weights_res_set10.h5')\n",
    "    else:\n",
    "        raise Exception(\"Sorry, model_type allowed are 'mobile' (MobileNet), 'dense' (DenseNet) \\\n",
    "        or 'res' (ResNet50)\")\n",
    "        \n",
    "    print(\"Model Loaded\")\n",
    "    \n",
    "    if pt is None:\n",
    "        # For unperturbed\n",
    "        img = Image.open(image_fn)\n",
    "    elif pt == 'g':\n",
    "        # For glasses\n",
    "        apply_glasses(image_fn)\n",
    "        img = Image.open(image_fn+{}).format(pt)\n",
    "    elif pt == 'mu':\n",
    "        # For makeup\n",
    "        apply_makeup(image_fn)\n",
    "        img = Image.open(image_fn+{}).format(pt)\n",
    "    elif pt == 'msk':\n",
    "        # For masked\n",
    "        apply_mask(image_fn)\n",
    "        img = Image.open(image_fn+{}).format(pt)\n",
    "    \n",
    "    img = img.resize((224, 224))\n",
    "    img = np.array(img)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    confidence = model.predict(img)\n",
    "    res = [1 if confidence > 0.5 else 0][0]\n",
    "    \n",
    "    if pt is not None:\n",
    "        pass\n",
    "    \n",
    "    if res == 1:\n",
    "        return (\"Male\", confidence)\n",
    "    elif res == 0:\n",
    "        return (\"Female\", 1 - confidence)\n",
    "    else:\n",
    "        raise Exception(\"Issue during prediction occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed78d71-5a6b-48b7-a546-aac67a8f1df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Female', array([[0.99792165]], dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pred('gal.jpeg', 'mobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8ea7f-7803-470b-8b7a-8a771ef5613c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
