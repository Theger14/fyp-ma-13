{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb14905-e4ff-4125-aa27-82fda442555a",
   "metadata": {},
   "source": [
    "### This script contains:\n",
    "- gen_metrics() : Returns classification report and confusion matrix (sklearn.metrics)\n",
    "- gen_save_cr_cm() : Generates, saves and returns classification reports and confusion matrix\n",
    "- make_pred() : Returns predicted class and confidence for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf1ad25-1567-4016-ba5a-baf0b971e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import imp\n",
    "\n",
    "from subprocess import call         # To call mask filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66be95f7-58ed-45ee-b758-4af8f0ca7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1156ad-07fc-441c-8d9f-6e39b326252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "IMG_SIZE = (224,224)\n",
    "LABELS = [\"female\", \"male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2a0d8c-547a-4f25-bdd9-d4088437cd91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_metrics(model_type, all_models, original_fp, perturbation='all', gender=None):\n",
    "    \"\"\"\n",
    "    Returns classification report and confusion matrix (sklearn.metrics)\n",
    "    \n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    all_models : list\n",
    "        List of models i.e. [mobilenet, densenet, resnet]\n",
    "    original_fp : str\n",
    "        Original image file path\n",
    "    perturbation: str\n",
    "        Perturbation type. Either 'ori', 'masked', 'glasses', 'make_up' or 'all'\n",
    "    gender : str\n",
    "        Gender. Either None, 'male' or female to specify the gender. If None it make predictions on both.\n",
    "    \"\"\"\n",
    "    # FEMALE => 0\n",
    "    # MALE => 1\n",
    "    \n",
    "    # Set model\n",
    "    if (model_type == \"mobile\"):\n",
    "        model = all_models[0]\n",
    "    elif (model_type == \"dense\"):\n",
    "        model = all_models[1]\n",
    "    elif (model_type == \"res\"):\n",
    "        model = all_models[2]\n",
    "    else:\n",
    "        raise Exception(\"Sorry, model_type allowed are 'mobile' (MobileNet), 'dense' (DenseNet) \\\n",
    "        or 'res' (ResNet50)\")\n",
    "    assert gender in [None, 'male', 'female'], \"gender needs to be None, 'male' or 'female'\"\n",
    "    \n",
    "    datasets = [\"test\", \"test_masked\", \"test_glasses\", \"test_makeup\"]\n",
    "    # If we only want ont type of perturbation\n",
    "    if perturbation != 'all':\n",
    "        assert perturbation in ['ori', 'masked', 'glasses', 'makeup']\n",
    "        if perturbation == 'ori':\n",
    "            datasets = [\"test\"]\n",
    "        else:\n",
    "            datasets = [\"test_\"+perturbation]\n",
    "    \n",
    "    for i in tqdm(range(len(datasets)), 'Testing...'):\n",
    "        data_name = datasets[i]\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        male_dir = os.listdir(original_fp + data_name + \"/male\")\n",
    "        female_dir = os.listdir(original_fp + data_name + \"/female\")\n",
    "        \n",
    "        if gender is None:\n",
    "            for j in range(len(male_dir)):\n",
    "                fn = male_dir[j]\n",
    "                img = Image.open(original_fp + data_name + \"/male/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(1)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "\n",
    "            for k in range(len(female_dir)):\n",
    "                fn = female_dir[k]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/female/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(0)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "        elif gender == 'male':\n",
    "            for j in range(len(male_dir)):\n",
    "                fn = male_dir[j]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/male/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(1)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "        elif gender == 'female':\n",
    "            for k in range(len(female_dir)):\n",
    "                fn = female_dir[k]\n",
    "                img = Image.open(preprocessing_fp + data_name + \"/female/\" + fn)\n",
    "                img = img.resize((224, 224))\n",
    "                img = np.array(img)\n",
    "                img = np.expand_dims(img, 0)\n",
    "\n",
    "                y_true.append(0)\n",
    "                y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "\n",
    "        cr = classification_report(y_true, y_pred, zero_division = 1)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "    return cr, cm\n",
    "\n",
    "def gen_save_cr_cm(model_type, all_models, original_fp, target_fp, perturbation='all', gender=None):\n",
    "    \"\"\"\n",
    "    Generates, saves and returns classification reports and confusion matrix\n",
    "    \n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    all_models : list\n",
    "        List of models i.e. [mobilenet, densenet, resnet]\n",
    "    original_fp : str\n",
    "        Original image file path\n",
    "    target_fp : str\n",
    "        Target file path to save results\n",
    "    perturbation: str\n",
    "        Either 'ori', 'masked', 'glasses', 'make_up' or 'all'\n",
    "    gender : str\n",
    "        Either None, 'male' or female to specify the gender. If None it make predictions on both.\n",
    "    \"\"\"\n",
    "    assert model_type in ['mobile', 'dense', 'res'], 'Incorrect model_type param value'\n",
    "    assert gender in [None, 'male', 'female'], 'Incorrect gender param value'\n",
    "    \n",
    "    # Assign to appropriate folder\n",
    "    if perturbation != 'all':\n",
    "        assert perturbation in ['ori', 'masked', 'glasses', 'makeup']\n",
    "    \n",
    "    temp = gender\n",
    "    if temp is None: # Checks if it is for all genders\n",
    "        temp = 'bothg'\n",
    "    x = target_fp+'cr_cm_{}_{}_{}'.format(model_type, perturbation, temp)\n",
    "    if path.exists(x):    # if it already exists\n",
    "        print(x + \" already exists, pass\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(\"Creating \" + x +\"...\")\n",
    "\n",
    "    cr, cm = gen_metrics(model_type, all_models, original_fp, perturbation, gender=gender)\n",
    "    \n",
    "    # If we only want one type of perturbation\n",
    "    if gender == None:\n",
    "        gender = 'bothg'\n",
    "    # Dumps metrics into a JSON object\n",
    "    res = {\"cr_{}_{}\".format(model_type, gender): cr, \n",
    "           \"cm_{}_{}\".format(model_type, gender): cm.tolist()}\n",
    "    j = json.dumps(res, indent = 4)\n",
    "    \n",
    "    # Save as JSON object\n",
    "    fn = Path(target_fp+'cr_cm_{}_{}_{}'.format(model_type, perturbation, gender))\n",
    "    if not fn.is_dir():\n",
    "        with open(target_fp+'cr_cm_{}_{}_{}'.format(model_type, perturbation, gender), 'w') as outfile:\n",
    "            json.dump(j, outfile)\n",
    "    return cr, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc4a9a-2d43-47e4-9699-d3458816987f",
   "metadata": {},
   "source": [
    "# Make individual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3084aaeb-c2d4-4c9b-84ef-2e54d3eff820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in glasses filter module\n",
    "glasses_mod = imp.load_source('apply_glasses', '/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/preprocessing/perturb_filters/glasses/put_glasses.py')\n",
    "makeup_mod = imp.load_source('apply_makeup', '/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/preprocessing/gen_perturbed_test_sets.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67bdf65a-3a90-4b31-a553-2d8d9b0b01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation functions\n",
    "def apply_filter(original_fp, target_fp, filter_type):\n",
    "    \"\"\"\n",
    "    Applies a desired filter to specific image\n",
    "    \n",
    "    image_fp : str\n",
    "        File path containing image\n",
    "    target_fp : str\n",
    "        Target path to folder to store image\n",
    "    \"\"\"\n",
    "    spl = original_fp.split(\"/\")\n",
    "    \n",
    "    try:\n",
    "        if filter_type == \"glasses\":\n",
    "            # Call apply_glasses from the glasses module\n",
    "            glasses_mod.apply_glasses('/'.join(spl[:-1]), spl[-1], target_fp)\n",
    "        elif filter_type == \"makeup\":\n",
    "            makeup_mod.apply_makeup('/'.join(spl[:-1]), spl[-1], target_fp)\n",
    "        elif filter_type == \"mask\":\n",
    "            print(\"Original fp:\", original_fp)\n",
    "            status = call(\"python mask_the_face.py --path {} --mask_type 'N95' --verbose\".format(original_fp),\n",
    "                    cwd=\"/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/preprocessing/perturb_filters/mask\", \n",
    "                    shell=True)\n",
    "            \n",
    "            # Move saved image to target_fp\n",
    "            mask_image_fp = '_N95.'.join(spl[-1].split(\".\"))\n",
    "            os.rename('/'.join(spl[:-1]) + \"/\" + mask_image_fp, target_fp + spl[-1])\n",
    "            print(\"Moved image to temp folder\", status)\n",
    "        else: raise Exception(\"filter_type is not accepted\")\n",
    "        print(\"Success!\")\n",
    "    except Exception as e:\n",
    "        print(\"Please try Again.\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b1ef4c9-db86-42be-bb1d-e1ee0b2681b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet = tf.keras.models.load_model('model_tl_best_weights_mobile.h5')\n",
    "# densenet = tf.keras.models.load_model('model_tl_best_weights_dense.h5')\n",
    "# resnet = tf.keras.models.load_model('model_tl_best_weights_res.h5')\n",
    "# all_models = [mobilenet, densenet, resnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b53d15-e0ec-4c2d-b04a-6d49c3995951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(image_fn, model_type, debiased=False, pt=None):\n",
    "    \"\"\"\n",
    "    Returns predicted class and confidence for a single image\n",
    "    \n",
    "    image_fn : str\n",
    "        Path to image\n",
    "    model_type : str\n",
    "        Either 'mobile' (MobileNet), 'dense' (DenseNet) or 'res' (ResNet50)\n",
    "    pt : str\n",
    "        Perturbation type (default = None)\n",
    "    \"\"\"\n",
    "    model_path = '/home/monash/Desktop/fyp-work/fyp-ma-13/fyp-models/timeline/{}/best_weights/set10/model_tl_best_weights_{}_set10.h5'\n",
    "    # Set model\n",
    "    if (model_type == \"mobile\") or (model_type == \"dense\") or (model_type == \"res\"):\n",
    "        if not debiased:\n",
    "            model = tf.keras.models.load_model(model_path.format(\"(8)_debiased_25\", model_type))\n",
    "        else:\n",
    "            model = tf.keras.models.load_model(model_path.format(\"(5)_early_stopping_20\", model_type))\n",
    "    else:\n",
    "        raise Exception(\"Sorry, model_type allowed are 'mobile' (MobileNet), 'dense' (DenseNet) \\\n",
    "        or 'res' (ResNet50)\")\n",
    "        \n",
    "    print(model_type, \"loaded\")\n",
    "    \n",
    "    if pt is None:\n",
    "        # For unperturbed\n",
    "        img = Image.open(image_fn)\n",
    "    elif pt == 'g':\n",
    "        # For glasses\n",
    "        apply_glasses(image_fn)\n",
    "        img = Image.open(image_fn+{}).format(pt)\n",
    "    elif pt == 'mu':\n",
    "        # For makeup\n",
    "        apply_makeup(image_fn)\n",
    "        img = Image.open(image_fn+{}).format(pt)\n",
    "    elif pt == 'msk':\n",
    "        # For masked\n",
    "        apply_mask(image_fn)\n",
    "        img = Image.open(image_fn+{}).format(pt)\n",
    "    \n",
    "    img = img.resize((224, 224))\n",
    "    img = np.array(img)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    confidence = model.predict(img)\n",
    "    res = [1 if confidence > 0.5 else 0][0]\n",
    "    \n",
    "    if pt is not None:\n",
    "        pass\n",
    "    \n",
    "    if res == 1:\n",
    "        return (\"Male\", confidence)\n",
    "    elif res == 0:\n",
    "        return (\"Female\", 1 - confidence)\n",
    "    else:\n",
    "        raise Exception(\"Issue during prediction occured\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
